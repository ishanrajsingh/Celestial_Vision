import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, Subset, random_split
from torchvision import transforms
from torchvision.models import resnet50, ResNet50_Weights, efficientnet_b3, EfficientNet_B3_Weights
from PIL import Image, UnidentifiedImageError
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import numpy as np
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
from copy import deepcopy
import warnings
warnings.filterwarnings('ignore')

class AstronomicalImageDataset(Dataset):
    def __init__(self, root_directory, transform=None, validate_images=True):
        self.root_directory = root_directory
        self.transform = transform
        self.class_names = sorted([folder for folder in os.listdir(root_directory) 
                                   if os.path.isdir(os.path.join(root_directory, folder))])
        self.class_mapping = {name: idx for idx, name in enumerate(self.class_names)}        
        self.image_paths = []
        self.target_labels = []
        corrupted_count = 0
        
        for class_name in self.class_names:
            class_directory = os.path.join(root_directory, class_name)
            for image_file in os.listdir(class_directory):
                if not image_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
                    corrupted_count += 1
                    continue
                
                full_image_path = os.path.join(class_directory, image_file)
                
                if validate_images:
                    try:
                        with Image.open(full_image_path) as img:
                            img.verify()
                        self.image_paths.append(full_image_path)
                        self.target_labels.append(self.class_mapping[class_name])
                    except (IOError, SyntaxError, UnidentifiedImageError):
                        corrupted_count += 1
                else:
                    self.image_paths.append(full_image_path)
                    self.target_labels.append(self.class_mapping[class_name])
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, index):
        image_path = self.image_paths[index]
        try:
            image = Image.open(image_path).convert('RGB')
        except Exception:
            image = Image.new('RGB', (224, 224), (0, 0, 0))
        
        label = self.target_labels[index]
        
        if self.transform:
            image = self.transform(image)
        
        return image, label

advanced_train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.3),
    transforms.RandomRotation(degrees=45),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.15),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),
    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    transforms.RandomErasing(p=0.3, scale=(0.02, 0.15))
])

validation_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


class OptimizedAstronomyClassifier(nn.Module):
    def __init__(self, num_classes, dropout_rate=0.5, use_efficientnet=False):
        super(OptimizedAstronomyClassifier, self).__init__()
        
        if use_efficientnet:
            self.backbone = efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1)
            
            for param in self.backbone.parameters():
                param.requires_grad = False
            for param in self.backbone.features[-3:].parameters():
                param.requires_grad = True
            
            num_features = self.backbone.classifier[1].in_features
            self.backbone.classifier = nn.Sequential(
                nn.Dropout(p=dropout_rate, inplace=True),
                nn.Linear(num_features, 768),
                nn.BatchNorm1d(768),
                nn.ReLU(inplace=True),
                nn.Dropout(p=dropout_rate * 0.7),
                nn.Linear(768, 384),
                nn.BatchNorm1d(384),
                nn.ReLU(inplace=True),
                nn.Dropout(p=dropout_rate * 0.5),
                nn.Linear(384, num_classes)
            )
        else:
            self.backbone = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)
            
            for param in self.backbone.parameters():
                param.requires_grad = False
            for param in self.backbone.layer3.parameters():
                param.requires_grad = True
            for param in self.backbone.layer4.parameters():
                param.requires_grad = True
            
            num_features = self.backbone.fc.in_features
            self.backbone.fc = nn.Sequential(
                nn.Linear(num_features, 1024),
                nn.BatchNorm1d(1024),
                nn.ReLU(inplace=True),
                nn.Dropout(p=dropout_rate),
                nn.Linear(1024, 512),
                nn.BatchNorm1d(512),
                nn.ReLU(inplace=True),
                nn.Dropout(p=dropout_rate * 0.7),
                nn.Linear(512, num_classes)
            )
    
    def forward(self, x):
        return self.backbone(x)


class EarlyStopping:
    def __init__(self, patience=7, min_delta=0.0, verbose=True):
        self.patience = patience
        self.min_delta = min_delta
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.best_model_weights = None
    
    def __call__(self, val_accuracy, model):
        score = val_accuracy
        
        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(model)
        elif score < self.best_score + self.min_delta:
            self.counter += 1
            if self.verbose:
                print(f'EarlyStopping counter: {self.counter}/{self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(model)
            self.counter = 0
    
    def save_checkpoint(self, model):
        self.best_model_weights = deepcopy(model.state_dict())


def mixup_data(x, y, alpha=0.2):

    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
    
    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)
    
    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam


def mixup_criterion(criterion, pred, y_a, y_b, lam):
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)


dataset_path = '/kaggle/input/spacenet-an-optimally-distributed-astronomy-data/SpaceNet.FLARE.imam_alam'

complete_dataset = AstronomicalImageDataset(root_directory=dataset_path, transform=None)

print(f"Dataset Statistics:")
print(f"Class Names: {complete_dataset.class_names}")
print(f"Total Samples: {len(complete_dataset)}")
print(f"Number of Classes: {len(complete_dataset.class_names)}")

torch.manual_seed(42)
train_split_size = int(0.8 * len(complete_dataset))
val_split_size = len(complete_dataset) - train_split_size
train_indices, val_indices = random_split(
    complete_dataset, 
    [train_split_size, val_split_size]
)

# Create separate datasets with appropriate transforms
class TransformedSubset(Dataset):
    """Wrapper to apply different transforms to subsets"""
    def __init__(self, base_dataset, indices, transform):
        self.base_dataset = base_dataset
        self.indices = indices
        self.transform = transform
    
    def __len__(self):
        return len(self.indices)
    
    def __getitem__(self, idx):
        actual_idx = self.indices[idx]
        image_path = self.base_dataset.image_paths[actual_idx]
        label = self.base_dataset.target_labels[actual_idx]
        
        try:
            image = Image.open(image_path).convert('RGB')
        except Exception:
            image = Image.new('RGB', (224, 224), (0, 0, 0))
        
        if self.transform:
            image = self.transform(image)
        
        return image, label

train_dataset = TransformedSubset(complete_dataset, train_indices.indices, advanced_train_transform)
val_dataset = TransformedSubset(complete_dataset, val_indices.indices, validation_transform)

train_loader = DataLoader(
    train_dataset, 
    batch_size=32,
    shuffle=True, 
    num_workers=4, 
    pin_memory=True,
    persistent_workers=True
)

val_loader = DataLoader(
    val_dataset, 
    batch_size=32, 
    shuffle=False, 
    num_workers=4, 
    pin_memory=True,
    persistent_workers=True
)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model = OptimizedAstronomyClassifier(
    num_classes=len(complete_dataset.class_names),
    dropout_rate=0.5,
    use_efficientnet=False  # Set to True to use EfficientNet-B3
).to(device)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
optimizer = optim.AdamW(
    model.parameters(), 
    lr=0.0005,  # Lower learning rate
    weight_decay=0.01,  # Increased weight decay
    betas=(0.9, 0.999)
)

scheduler = CosineAnnealingWarmRestarts(
    optimizer, 
    T_0=10,  # Restart every 10 epochs
    T_mult=2,  # Double the period after each restart
    eta_min=1e-6
)

early_stopping = EarlyStopping(patience=10, min_delta=0.1, verbose=True)

def train_one_epoch(model, dataloader, criterion, optimizer, device, use_mixup=True):
    model.train()
    running_loss = 0.0
    correct_predictions = 0
    total_samples = 0
    
    for images, labels in dataloader:
        images, labels = images.to(device), labels.to(device)
        
        if use_mixup and np.random.rand() > 0.5:
            images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=0.2)
            optimizer.zero_grad()
            outputs = model(images)
            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)
        else:
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
        
        loss.backward()
        
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        
        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total_samples += labels.size(0)
        correct_predictions += (predicted == labels).sum().item()
    
    epoch_loss = running_loss / len(dataloader)
    epoch_accuracy = 100 * correct_predictions / total_samples
    return epoch_loss, epoch_accuracy


def validate(model, dataloader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct_predictions = 0
    total_samples = 0
    
    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total_samples += labels.size(0)
            correct_predictions += (predicted == labels).sum().item()
    
    val_loss = running_loss / len(dataloader)
    val_accuracy = 100 * correct_predictions / total_samples
    return val_loss, val_accuracy


NUM_EPOCHS = 50
history = {
    'train_loss': [],
    'train_acc': [],
    'val_loss': [],
    'val_acc': []
}


best_validation_accuracy = 0.0

for epoch in range(NUM_EPOCHS):
    train_loss, train_acc = train_one_epoch(
        model, train_loader, criterion, optimizer, device, use_mixup=True
    )
    
    val_loss, val_acc = validate(model, val_loader, criterion, device)
    
    scheduler.step()
    
    history['train_loss'].append(train_loss)
    history['train_acc'].append(train_acc)
    history['val_loss'].append(val_loss)
    history['val_acc'].append(val_acc)
    
    print(f"Epoch [{epoch+1:3d}/{NUM_EPOCHS}] | "
          f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:6.2f}% | "
          f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:6.2f}% | "
          f"LR: {optimizer.param_groups[0]['lr']:.6f}")
    
    if val_acc > best_validation_accuracy:
        best_validation_accuracy = val_acc
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'val_acc': val_acc,
        }, 'best_astronomy_model.pth')
        print(f"Validation Accuracy: {val_acc:.2f}%")
    
    early_stopping(val_acc, model)
    if early_stopping.early_stop:
        model.load_state_dict(early_stopping.best_model_weights)
        break

print(f"Best Validation Accuracy: {best_validation_accuracy:.2f}%")

plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.plot(history['train_loss'], label='Training Loss', linewidth=2)
plt.plot(history['val_loss'], label='Validation Loss', linewidth=2)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('Loss', fontsize=12)
plt.title('Model Loss', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(1, 3, 2)
plt.plot(history['train_acc'], label='Training Accuracy', linewidth=2)
plt.plot(history['val_acc'], label='Validation Accuracy', linewidth=2)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('Accuracy (%)', fontsize=12)
plt.title('Model Accuracy', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(1, 3, 3)
plt.plot([optimizer.param_groups[0]['lr']] * len(history['train_loss']), linewidth=2)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('Learning Rate', fontsize=12)
plt.title('Learning Rate Schedule', fontsize=14, fontweight='bold')
plt.yscale('log')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()


model.eval()
all_predictions = []
all_true_labels = []
all_probabilities = []

with torch.no_grad():
    for images, labels in val_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        probabilities = torch.softmax(outputs, dim=1)
        _, predictions = torch.max(outputs, 1)
        
        all_predictions.extend(predictions.cpu().numpy())
        all_true_labels.extend(labels.cpu().numpy())
        all_probabilities.extend(probabilities.cpu().numpy())

cm = confusion_matrix(all_true_labels, all_predictions)
plt.figure(figsize=(12, 10))
sns.heatmap(
    cm, 
    annot=True, 
    fmt='d', 
    cmap='YlOrRd',
    xticklabels=complete_dataset.class_names,
    yticklabels=complete_dataset.class_names,
    cbar_kws={'label': 'Count'}
)
plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')
plt.ylabel('True Label', fontsize=12, fontweight='bold')
plt.title('Confusion Matrix - Validation Set', fontsize=14, fontweight='bold')
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

print(classification_report(
    all_true_labels, 
    all_predictions, 
    target_names=complete_dataset.class_names,
    digits=4
))

final_accuracy = 100 * np.sum(np.array(all_predictions) == np.array(all_true_labels)) / len(all_true_labels)
print(f"FINAL VALIDATION ACCURACY: {final_accuracy:.2f}%")

misclassified_indices = np.where(np.array(all_predictions) != np.array(all_true_labels))[0]

if len(misclassified_indices) > 0:
    
    num_examples = min(12, len(misclassified_indices))
    fig, axes = plt.subplots(3, 4, figsize=(16, 12))
    axes = axes.flatten()
    
    for i, idx in enumerate(misclassified_indices[:num_examples]):
        img, true_label = val_dataset[idx]
        pred_label = all_predictions[idx]
        confidence = all_probabilities[idx][pred_label] * 100
        
        img_denorm = img.clone()
        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
        img_denorm = img_denorm * std + mean
        img_denorm = img_denorm.clamp(0, 1).permute(1, 2, 0).numpy()
        
        axes[i].imshow(img_denorm)
        axes[i].set_title(
            f"True: {complete_dataset.class_names[true_label]}\n"
            f"Pred: {complete_dataset.class_names[pred_label]} ({confidence:.1f}%)",
            fontsize=10,
            color='red'
        )
        axes[i].axis('off')
    
    plt.suptitle('Misclassified Examples', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()
